## Phase 2 and 3 breakdown:

### Phase 2:

1. Data Collection:
   > `bs4` (maybe)
2. Tokenization:
   > `NLTK`
3. NER:
   > `NLTK`
4. POS:
   > `NLTK`
5. Match and format the extracted data's fields with the data dictionary. Keep relevant fields only.
6. Data cleansing: deduplication
   > `drop_duplicates()`
7. CFS:
   > `SelectKBest` in `SciKit-Learn`
8. Firefly Algo:
   > `PySwarm`
9. Data manipulation & pre-processing:
   > `Pandas`
10. Neural Networks building:
    > `TensorFlow` or `Keras`
11. Model evaluation & metrics:
    > `SciKit-learn`
12. Text to numerical:
    > `Word2Vec` in `gensim` library
13. TF-IDF:
    > `TfidfVectorizer` in `SciKit-learn`
14. Padding/Truncating:
    > `pad_sequences` in `Keras` (will find something from `tensorFlow` later)
15. Model building:
    > `tensorFlow` or `Keras`
16. Training and evaluation of model:
    > `fit` and `evaluate` in `Keras` (will find something from tensorFlow later)
